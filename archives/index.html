<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>Archives | GenAI Crew</title>
<meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="A collection of GenAI-related posts"><meta name=generator content="Hugo 0.146.0"><meta name=robots content="index, follow"><meta name=author content="GenAI Crew"><link rel=stylesheet href=/ananke/css/main.min.d05fb5f317fcf33b3a52936399bdf6f47dc776516e1692e412ec7d76f4a5faa2.css><link href=/archives/index.xml rel=alternate type=application/rss+xml title="GenAI Crew"><link href=/archives/index.xml rel=feed type=application/rss+xml title="GenAI Crew"><link rel=canonical href=https://juananpe.github.io/archives/><meta property="og:url" content="https://juananpe.github.io/archives/"><meta property="og:site_name" content="GenAI Crew"><meta property="og:title" content="Archives"><meta property="og:description" content="Welcome to our archives! Here you’ll find all our previous posts about Generative AI, excluding the most recent ones that are featured on the homepage."><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><meta itemprop=name content="Archives"><meta itemprop=description content="Welcome to our archives! Here you’ll find all our previous posts about Generative AI, excluding the most recent ones that are featured on the homepage."><meta itemprop=wordCount content="25"><meta name=twitter:card content="summary"><meta name=twitter:title content="Archives"><meta name=twitter:description content="Welcome to our archives! Here you’ll find all our previous posts about Generative AI, excluding the most recent ones that are featured on the homepage."></head><body class="ma0 avenir bg-near-white production"><header><div class="pb3-m pb6-l bg-black"><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l center items-center justify-between"><a href=/ class="f3 fw2 hover-white white-90 dib no-underline">GenAI Crew</a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white white-90 no-underline" href=/ title="Home page">Home</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white white-90 no-underline" href=/archives/ title="Archives page">Archives</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white white-90 no-underline" href=/tags/ title="Tags page">Tags</a></li></ul><div class=ananke-socials></div></div></div></nav><div class="tc-l pv3 ph3 ph4-ns"><h1 class="f2 f-subheadline-l fw2 light-silver mb0 lh-title">Archives</h1></div></div></header><main class=pb7 role=main><article class="pa3 pa4-ns"><header><h1 class="f1 lh-title">Archives</h1><div class="f4 nested-copy-line-height nested-links"><p>Welcome to our archives! Here you&rsquo;ll find all our previous posts about Generative AI, excluding the most recent ones that are featured on the homepage.</p></div></header><section class="flex-ns flex-wrap justify-around mt5"><div class="relative w-100 w-30-l mb4 bg-white"><div class="mb3 pa4 mid-gray overflow-hidden"><div class=f6>April 27, 2025</div><h1 class="f3 near-black"><a href=/posts/gemini-caching/ class="link black dim">Gemini Context Caching Explained</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><p>Context caching in Gemini allows you to store and pre-compute context, such as documents or even entire code repositories. This cached context can then be reused in subsequent requests, leading to significant cost savings – potentially up to 75%.</p><p>For example, using Gemini 1.5 Pro, caching a full GitHub repository and then asking follow-up questions about it demonstrates this capability. Each subsequent request utilizing the same cache could cost substantially less ($0.31 vs. $1.25 per 1 million tokens, according to the tweet).</p></div><a href=/posts/gemini-caching/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div><div class="relative w-100 w-30-l mb4 bg-white"><div class="mb3 pa4 mid-gray overflow-hidden"><div class=f6>April 27, 2025</div><h1 class="f3 near-black"><a href=/posts/intellect-2/ class="link black dim">Intellect-2: First Decentralized 32B RL Training Complete</a></h1><div class="nested-links f5 lh-copy nested-copy-line-height"><p>Prime Intellect (<a href=https://x.com/PrimeIntellect>@PrimeIntellect</a>) announced the completion of INTELLECT-2, the first decentralized Reinforcement Learning (RL) training run for a 32-billion-parameter model.</p><figure><img src=/images/intellect2.png alt="Intellect-2 Training Progress"></figure><p><strong>Key Points:</strong></p><ul><li><strong>Milestone:</strong> This marks the first successful decentralized RL training of a 32B model.</li><li><strong>Open Collaboration:</strong> The training was open to compute contributions from anyone, making it fully permissionless.</li><li><strong>Goal:</strong> The project aims to scale towards frontier reasoning capabilities in areas like coding, math, and science.</li><li><strong>Upcoming Release:</strong> A full open-source release, including model checkpoints, training data, and a detailed technical report, is expected approximately one week after the announcement (made around late August 2024).</li><li><strong>Community Effort:</strong> The announcement highlighted the significant contributions from various compute providers, including Demeter<em>compute, string, BioProtocol, mev_pete, plaintext_cap, skre_0, oldmankotaro, plabs, ibuyrugs, 0xfr</em>, marloXBT, herb0x_, mo, toptickcrypto, cannopo, samsja19, jackminong, and primeprimeint1234.</li></ul><p><strong>Links:</strong></p></div><a href=/posts/intellect-2/ class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a></div></div></section></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href=https://juananpe.github.io/>&copy; GenAI Crew 2025</a><div><div class=ananke-socials></div></div></div></footer></body></html>